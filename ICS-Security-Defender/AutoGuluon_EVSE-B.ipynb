{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/anaconda3/envs/AutoML/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115298, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the directory containing your CSV files\n",
    "\n",
    "directory_path = '/home/danish/Datasets/EVSE-B'\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and concatenate its data to the combined DataFrame\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    df = pd.read_csv(file_path).dropna()\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "data = combined_df # .sample(frac=0.5, random_state=42)\n",
    "data.shape\n",
    "# Optionally, you can save the combined DataFrame to a new CSV file\n",
    "# combined_df.to_csv('/path/to/combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'shunt_voltage',\n",
       " 'bus_voltage_V',\n",
       " 'current_mA',\n",
       " 'power_mW',\n",
       " 'State',\n",
       " 'Attack',\n",
       " 'Attack-Group',\n",
       " 'Label',\n",
       " 'interface']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack-Group\n",
       "DoS            34884\n",
       "recon          33318\n",
       "host-attack    32733\n",
       "none           14363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['shunt_voltage', 'bus_voltage_V', 'current_mA', 'power_mW', 'Attack-Group']]\n",
    "data['Attack-Group'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = TabularDataset(data)\n",
    "\n",
    "# Define the target column name\n",
    "target_column = 'Attack-Group'\n",
    "\n",
    "# Split data into training and validation sets (e.g., 80% train, 20% validation)\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/home/danish/Codes/AutoML/Gluon_EVSE-B/\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize AutoGluon TabularPredictor\n",
    "predictor = TabularPredictor(label=target_column, path='/home/danish/Codes/AutoML/Gluon_EVSE-B/')  # Specify path to save models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"/home/danish/Codes/AutoML/Gluon_EVSE-B/\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #41~22.04.2-Ubuntu SMP PREEMPT_DYNAMIC Mon Jun  3 11:32:55 UTC 2\n",
      "CPU Count:          128\n",
      "Memory Avail:       480.31 GB / 503.49 GB (95.4%)\n",
      "Disk Space Avail:   145.64 GB / 915.32 GB (15.9%)\n",
      "===================================================\n",
      "Train Data Rows:    92238\n",
      "Train Data Columns: 4\n",
      "Label Column:       Attack-Group\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['none', 'DoS', 'host-attack', 'recon']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    491760.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['bus_voltage_V']\n",
      "\t\t('int', [])   : 3 | ['shunt_voltage', 'current_mA', 'power_mW']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['bus_voltage_V']\n",
      "\t\t('int', [])   : 3 | ['shunt_voltage', 'current_mA', 'power_mW']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.027103796699841715, Train Rows: 89738, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.87s of the 3599.87s of remaining time.\n",
      "\t0.5844\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.51s of the 3599.51s of remaining time.\n",
      "\t0.5748\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3599.23s of the 3599.23s of remaining time.\n",
      "/home/danish/anaconda3/envs/AutoML/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "\t0.636\t = Validation score   (accuracy)\n",
      "\t48.62s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3550.53s of the 3550.53s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.3564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6444\t = Validation score   (accuracy)\n",
      "\t5.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3545.42s of the 3545.42s of remaining time.\n",
      "\t0.6552\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3544.37s of the 3544.37s of remaining time.\n",
      "\t0.6336\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3541.75s of the 3541.75s of remaining time.\n",
      "\t0.6356\t = Validation score   (accuracy)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3539.01s of the 3539.01s of remaining time.\n",
      "\t0.6464\t = Validation score   (accuracy)\n",
      "\t2.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3536.86s of the 3536.86s of remaining time.\n",
      "\t0.6524\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3534.54s of the 3534.54s of remaining time.\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3532.12s of the 3532.11s of remaining time.\n",
      "\t0.6608\t = Validation score   (accuracy)\n",
      "\t2.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3529.88s of the 3529.88s of remaining time.\n",
      "\t0.6512\t = Validation score   (accuracy)\n",
      "\t114.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3415.47s of the 3415.47s of remaining time.\n",
      "\t0.6608\t = Validation score   (accuracy)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3413.87s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 0.385, 'RandomForestGini': 0.154, 'KNeighborsUnif': 0.077, 'LightGBMXT': 0.077, 'LightGBM': 0.077, 'RandomForestEntr': 0.077, 'ExtraTreesGini': 0.077, 'LightGBMLarge': 0.077}\n",
      "\t0.664\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 186.32s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/danish/Codes/AutoML/Gluon_EVSE-B/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7427d8ca2d00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train_data=train_data, time_limit=3600)  # Set time_limit (in seconds) for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance:\n",
      "{'accuracy': 0.6506071118820468, 'balanced_accuracy': 0.6708131821906921, 'mcc': 0.5402363424675645}\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# labels = le.fit_transform(val_data['marker'])\n",
    "# labels\n",
    "\n",
    "# # print(y_true)\n",
    "# # print(y_pred)\n",
    "\n",
    "# val_data['marker'] = labels\n",
    "\n",
    "# Evaluate the trained model on the validation set\n",
    "performance = predictor.evaluate(val_data)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Validation Performance:\")\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
